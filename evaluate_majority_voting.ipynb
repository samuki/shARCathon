{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/csnlp/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3508\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[87], line 30\u001b[0m\n    result =  ast.literal_eval(result)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/csnlp/lib/python3.11/ast.py:64\u001b[0m in \u001b[1;35mliteral_eval\u001b[0m\n    node_or_string = parse(node_or_string.lstrip(\" \\t\"), mode='eval')\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/miniconda3/envs/csnlp/lib/python3.11/ast.py:50\u001b[0;36m in \u001b[0;35mparse\u001b[0;36m\n\u001b[0;31m    return compile(source, filename, mode, flags,\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<unknown>:1\u001b[0;36m\u001b[0m\n\u001b[0;31m    [[0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 5, 5, 5, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 5, 5, 5, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 5...\u001b[0m\n\u001b[0m                                                                                                                                                                                                                                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import ast\n",
    "\n",
    "folder = \"results/evaluation_small/no_replace_comma/gpt-3.5-turbo-16k\"\n",
    "\n",
    "result_files = os.listdir(folder)\n",
    "result_files = [os.path.join(folder, file) for file in result_files if os.path.splitext(file)[1] == \".json\"]\n",
    "accuracies = []\n",
    "\n",
    "for i, result_file in enumerate(result_files):\n",
    "\n",
    "    task_name = result_file.split(\"/\")[-1].split(\"_out\")[0]\n",
    "    true_task_path = os.path.join(\"data/evaluation_small/\", task_name + \".json\")\n",
    "\n",
    "    ground_truth = None \n",
    "\n",
    "    with open(true_task_path, \"r\") as f:\n",
    "        obj = json.loads(f.read())\n",
    "        ground_truth = obj[\"test\"][0][\"output\"]\n",
    "\n",
    "    with open(result_file, \"r\") as f:\n",
    "        results = json.loads(f.read())[\"output\"]\n",
    "\n",
    "        considered_results = []\n",
    "        dimensions = []\n",
    "\n",
    "        # for each result filter that all row dimensions are the same\n",
    "        for result in results:\n",
    "            try:\n",
    "                result =  ast.literal_eval(result)\n",
    "            except:\n",
    "                continue\n",
    "            d1 = len(result)\n",
    "            d2 = len(result[0])\n",
    "            invalid = False \n",
    "\n",
    "            for row in result: \n",
    "                \n",
    "                if len(row) != d2: \n",
    "                    invalid = True \n",
    "\n",
    "            if not invalid: \n",
    "                considered_results.append(result)\n",
    "                dimensions.append((d1, d2))\n",
    "\n",
    "\n",
    "        # perform majority voting on the number of dimensions\n",
    "        majority_dimension = max(dimensions,key=dimensions.count)\n",
    "        # filter to lists with majority dimension\n",
    "        considered_results = [result for result in considered_results if len(result) == majority_dimension[0] and len(result[0]) == majority_dimension[1]]\n",
    "\n",
    "        final_output = considered_results[0]\n",
    "        # majority voting on final output -> we perform character by character voting\n",
    "        for i in range(len(final_output)):\n",
    "            for j in range(len(final_output[0])):\n",
    "                \n",
    "                char_counter = []\n",
    "                for elm_list in considered_results:\n",
    "                    char_counter.append(elm_list[i][j])\n",
    "\n",
    "                max_character =  max(char_counter,key=char_counter.count)\n",
    "                final_output[i][j] = max_character\n",
    "\n",
    "        correct = True\n",
    "\n",
    "        for i in range(len(final_output)):\n",
    "            for j in range(len(final_output[0])):\n",
    "                try: \n",
    "                    if final_output[i][j] != ground_truth[i][j]:\n",
    "                        correct = False\n",
    "                except: \n",
    "                    correct = False\n",
    "\n",
    "        if correct: \n",
    "            accuracies.append(1)\n",
    "        else: \n",
    "            accuracies.append(0)\n",
    "\n",
    "print(\"accuracy\",  accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csnlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
